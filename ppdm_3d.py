# -*- coding: utf-8 -*-
"""PPDM_3D.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NaniW0Thobk-JdNuXFiptoQVxoQ_AZEY
"""

import pandas as pd
dt=pd.read_csv('/content/spambaseOriginal.csv',sep=',')
dt.head()

# select's only integer value fields
dt_base = dt.select_dtypes(include='number')
dt_base.head()

#grouping the triplets with column name

column_data = dt_base.columns
col_data=[]
for col in column_data:
  col_data.append(col)

triplets =[]
n= len(col_data)//3;
x = len(col_data)
m = len(col_data)
for i in range(0,m,3):
  trip=[]
  for j in range(3):
    if i+j>=m:break
    trip.append(col_data[i+j])
  triplets.append(trip)

mod = m%3
if mod==1:
  triplets[n].insert(1,col_data[x-2])
  triplets[n].insert(2,col_data[x-3])
elif mod==2:
   triplets[n].insert(2,col_data[x-2])

print(triplets)

#normalizing the whole data set

new_max=5.0
new_min=-0.1
attributes = dt_base.columns

for idx in attributes:
    min_value = dt_base[idx].dropna().min()
    max_value =dt_base[idx].dropna().max()

    dt_base[idx] = dt_base[idx].apply(lambda x:  ((x - min_value)/(max_value-min_value))*(new_max-new_min)+new_min)

print(dt_base)

#Appending all triplets in a list

final_triplets=[]
for i in triplets:
  final_triplets.append(dt_base[i])

print(final_triplets[0].head())

import numpy as np

a = np.radians(30)

def r_xy(theta):
    R_xy = np.array(( (np.cos(theta), 0 ,-np.sin(theta)),
               (np.sin(theta)*np.sin(theta), np.cos(theta) ,np.sin(theta)*np.cos(theta)),
               (np.sin(theta)*np.cos(theta),-np.sin(theta),np.cos(theta)*np.cos(theta)) ))
    return R_xy
print(r_xy(a))

def r_yz(theta):
    R_yz = np.array((  (np.cos(theta)*np.cos(theta), -np.sin(theta)*np.cos(theta) ,-np.sin(theta)),

                          (np.sin(theta), np.cos(theta) ,0),

               ( np.sin(theta)*np.cos(theta),-np.sin(theta)*np.sin(theta),np.cos(theta)) ))
    return R_yz
print(r_yz(a))

def r_xz(theta):
    R_xz =  np.array((  (np.cos(theta), -np.sin(theta) ,0),

                          (np.sin(theta)*np.cos(theta), np.cos(theta)*np.cos(theta) ,np.sin(theta)),

               ( -np.sin(theta)*np.sin(theta),np.sin(theta)*np.cos(theta),np.cos(theta)) ))
    return R_xz
print(r_xz(a))

#putting all rotation matrix into a array
rotation_matrix=[]

rotation_matrix.append(r_xy)
rotation_matrix.append(r_yz)
rotation_matrix.append(r_xz)

a = np.radians(30)
print(rotation_matrix[0](a))

#taking all angles from 1 to 360 into a list

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

angle=[]

for i in range(361):
  angle.append(i)

#this function takes argument {a triplet dataset , rotation angle list , rotation plane ,ex : r_xy plane , and column name of the corresponding triplet }
# returns data set of variance and angle of of difference of ( actual & perturbated) data set


def calculate (dataset , rotation_angle, rotation_func, col1 , col2 , col3,arr1=[],arr2=[],arr3=[]):
   for rotate in rotation_angle:
        theta=np.radians(rotate)
        new_triplet = dataset.copy()

        for row in range(len(new_triplet)):
              a=new_triplet.iloc[row].to_numpy()
              b = np.array([a])
              c = b.T
              rotation = np.dot(rotation_func(theta),c)

              new_triplet.at[row,col1] = rotation[0,0]
              new_triplet.at[row,col2] = rotation[1,0]
              new_triplet.at[row,col3] = rotation[2,0]

        variance=pd.DataFrame.var(dataset - new_triplet)
        arr1.append(variance[col1])
        arr2.append(variance[col2])
        arr3.append(variance[col3])

   data = {col1: arr1,
           col2: arr2,
           col3: arr3,
         'angle':rotation_angle
       }
   df = pd.DataFrame(data,columns=[col1,col2,col3,'angle'])
   if not df.empty:
      df.plot(x ='angle', y=[col1,col2,col3], kind = 'line')
      plt.show()

   return df

#takes argument (1.triplet , column name of this triplets , & threshold value for this triplet)
# returns a data set of satisfying angle values and corresponding triplet values of that angle

def check_threshold( dataset , col1, col2, col3,th1,th2,th3):
  threshold_arr1=[]
  threshold_arr2=[]
  threshold_arr3=[]
  threshold_angle=[]
  for row in range(len(dataset)):
    if (dataset.at[row,col1]>=th1) & (dataset.at[row,col2]>=th2) & (dataset.at[row,col3]>=th3):
      threshold_arr1.append(dataset.at[row,col1])
      threshold_arr2.append(dataset.at[row,col2])
      threshold_arr3.append(dataset.at[row,col3])
      threshold_angle.append(dataset.at[row,'angle'])

  data = {col1: threshold_arr1,
           col2: threshold_arr2,
           col3: threshold_arr3,
         'angle':threshold_angle
       }
  df = pd.DataFrame(data,columns=[col1,col2,col3,'angle'])

  return df

#FULLY AUTOMATED PROCESS
final_angles=[]

for i in range(len(rotation_matrix)):
    common_angle={}
    for j in range(len(final_triplets)):

        out1=calculate(final_triplets[j],angle,rotation_matrix[i],triplets[j][0],triplets[j][1],triplets[j][2],[],[],[])

        #out2=check_threshold(out1,triplets[j][0],triplets[j][1],triplets[j][2],0.5,0.5,0.5)
        angle_f = out1['angle'].to_numpy()

        for k in angle_f:
          if k in common_angle.keys():
            common_angle[k]+=1
          else:
            common_angle[k]=1
    new_angles=[]
    for key,value in common_angle.items(): #taking intersected angles for all triplet
        if value>=len(final_triplets):
            new_angles.append(key)

    final_angles.append(new_angles)
print(final_angles)

#this function rotate a dataset with corresponding angle (takes argument a triplet , rotation angle , rotation plane , column name of that triplet)

def rotation_function(dataset , rotation_angle, rotation_func, col1 , col2 , col3):
   for rotate in rotation_angle:
        theta=np.radians(rotate)
        new_triplet = dataset.copy()

        for row in range(len(new_triplet)):
              a=new_triplet.iloc[row].to_numpy()
              b = np.array([a])
              c=b.T
              rotation = np.dot(rotation_func(theta),c)

              new_triplet.at[row,col1] = rotation[0,0]
              new_triplet.at[row,col2] = rotation[1,0]
              new_triplet.at[row,col3] = rotation[2,0]

   return new_triplet

#Taking All common angle into a List and then finding maximum covariance for each angle

thresholdAngle=[]
for key in final_angles:
    thresholdAngle.append(key)

print("Angles" ,thresholdAngle)

max_covariance_angle=[]

for i in range(len(rotation_matrix)):

      max_CoVar=0
      max_Angle=0
      max_Rotation=0

      for tAngle in thresholdAngle[i]:
              all=[]
              all.append(tAngle)
              b = rotation_matrix[i]

              all_triplets=[]

              for xp in range(len(final_triplets)):
                    trip = rotation_function(final_triplets[xp],all,b,triplets[xp][0],triplets[xp][1],triplets[xp][2]);
                    all_triplets.append(trip)

              # triplet1 = rotation_function(final_triplets[0],all,b,triplets[0][0],triplets[0][1],triplets[0][2]);
              # triplet2 = rotation_function(final_triplets[1],all,b,triplets[1][0],triplets[1][1],triplets[1][2]);
              # triplet3 = rotation_function(final_triplets[2],all,b,triplets[2][0],triplets[2][1],triplets[2][2]);

              c=[];
              zz = len(final_triplets)-1
              if mod==1:
                  all_triplets[zz]=all_triplets[zz][triplets[zz][0]]

              for p1 in all_triplets:
                  c.append(p1)

              # c.append(triplet1);
              # c.append(triplet2);
              # c.append(triplet3);
              d = pd.concat(c,axis=1,join='inner');
              d1 = d.loc[:, ~d.columns.duplicated()]
              covMatrix = pd.DataFrame.cov(d1);
              summation=covMatrix.sum()
              x=summation.sum()

              if x>max_CoVar:
                max_CoVar=x
                max_Angle=tAngle
                max_Rotation = i
      store={
          "covariance":max_CoVar,
          "angle" : max_Angle,
          "rotation_plane":max_Rotation
      }
      max_covariance_angle.append(store)

print(max_covariance_angle)

# Final Perturbated Data SET
rotation_plane = 0
max_Angle=0

if max_covariance_angle[0]["covariance"]>max_covariance_angle[1]["covariance"] and max_covariance_angle[0]["covariance"]>max_covariance_angle[2]["covariance"]:
  rotation_plane=r_xy
  max_Angle= max_covariance_angle[0]["angle"]
elif max_covariance_angle[1]["covariance"]>max_covariance_angle[0]["covariance"] and max_covariance_angle[1]["covariance"]>max_covariance_angle[2]["covariance"]:
  rotation_plane=r_yz
  max_Angle= max_covariance_angle[1]["angle"]
else:
  rotation_plane=r_xz
  max_Angle= max_covariance_angle[2]["angle"]

#need to erase after work done
rotation_plane = 2
max_Angle = 16
final_Angle=[];
final_Angle.append(max_Angle)
c=[];

all_triplets=[]

for xp in range(len(final_triplets)):
    trip = rotation_function(final_triplets[xp],all,b,triplets[xp][0],triplets[xp][1],triplets[xp][2]);
    all_triplets.append(trip)


zz = len(final_triplets)-1
if mod==1:
   all_triplets[zz]=all_triplets[zz][triplets[zz][0]]


for p1 in all_triplets:
    c.append(p1)

# triplet_part1 = rotation_function(final_triplets[0],all,b,triplets[0][0],triplets[0][1],triplets[0][2]);
# triplet_part2 = rotation_function(final_triplets[1],all,b,triplets[1][0],triplets[1][1],triplets[1][2]);
# triplet_part3 = rotation_function(final_triplets[2],all,b,triplets[2][0],triplets[2][1],triplets[2][2]);

# if mod==1:
#      triplet_part3=triplet_part3[triplets[2][0]]
# elif mod==2:
#      triplet_part3=triplet_part3[triplets[2][0],triplets[2][1]]

# c.append(triplet_part1);
# c.append(triplet_part2);
# c.append(triplet_part3);

final_DATA_SET1 = pd.concat(c,axis=1,join='inner');
final_DATA_SET = final_DATA_SET1.loc[:, ~final_DATA_SET1.columns.duplicated()]
final_DATA_SET.to_csv('file.csv')

#Entropy Analysis :

import collections

from scipy.stats import entropy

def estimate_shannon_entropy(sequence):
    bases = collections.Counter([tmp_base for tmp_base in sequence])
    # define distribution
    dist = [x/sum(bases.values()) for x in bases.values()]

    # use scipy to calculate entropy
    entropy_value = entropy(dist, base=2)

    return entropy_value

#entropy of original dataset
entropy_original={}


for attrib in col_data:
  ent = estimate_shannon_entropy(dt_base[attrib])
  entropy_original[attrib]=ent

print("Entropy Original : ",entropy_original)

#entropy of perturb dataset
entropy_perturb={}

for attrib in col_data:
  ent = estimate_shannon_entropy(final_DATA_SET[attrib])
  entropy_perturb[attrib]=ent

print("Entropy Perturb : ",entropy_perturb)

#average entropy in perturb & original dataset

entropy_avg=0

for attrib in col_data:
  entropy_avg+=entropy_perturb[attrib]-entropy_original[attrib]
k = len(col_data)
entropy_avg /=k

print("Average Entropy : ",entropy_avg);

# -*- coding: utf-8 -*-
"""
Created on Mon Mar 11 20:01:35 2019

@author: AFSANA AFRIN
"""
import csv
import numpy as np
import math
from numpy import array
from numpy import diag
from numpy import dot
import random as ran
from numpy import zeros


def load_csv(filename):
	dataset = list()
	with open(filename, 'r') as file:
		csv_reader = csv.reader(file)
		for row in csv_reader:
			if not row:
				continue
			dataset.append(row)
	return dataset

filename = 'bank.csv'




dataset1 = final_DATA_SET
dataset1[dataset1<0]=dataset1*-1
C1=np.array(dataset1)
len3=len(C1[0])
B=np.array(C1[:,:len3-1])

B1=(np.array(B, dtype=float))
print(B1)
from sklearn.decomposition import NMF

model = NMF(n_components=4, init='random', random_state=0)
W = model.fit_transform(B1)
H = model.components_

B3 = W.dot(H)

B4=np.array(C1)
for i in range(len(B1)):
    for j in range(len(B1[0])):
        B4[i][j]=B3[i][j]


#print(B3)
#print(B5)

#privacy
#VD
len1=len(B1)
len2=len(B1[0])
val1=0
value=0
val=0
for i in range(len(B1)):
    for j in range(len(B1[0])):
        value=B1[i][j]-B3[i][j]
        val+=pow(value,2)
q=math.sqrt(val)
for i in range(len1):
    for j in range(len2):
        value=B1[i][j]
        val1+=pow(value,2)
q1=math.sqrt(val1)

print('VD',q/q1)

tB=np.transpose(B1)
tB1=np.transpose(B3)

tB2=(tB.argsort(1)).argsort(1)
tB3=(tB1.argsort(1)).argsort(1)

C=abs(tB2-tB3)
D=C.sum()

RP=D/(len1*len2)
print('RP',RP)

count=0
for i in range(len2):
    for j in range(len1):
        if(C[i][j]==0):
            count+=1
RK=count/(len1*len2)
print('RK',RK)

ad=[]
a=0
for i in tB:
    D=i.sum()
    ad.append(D)

output = [0] * len(ad)
for i, x in enumerate(sorted(range(len(ad)), key=lambda y: ad[y])):
    output[x] = i


ad1=[]
for i in tB1:
    D=i.sum()
    ad1.append(D)

output1 = [0] * len(ad1)
for i, x in enumerate(sorted(range(len(ad1)), key=lambda y: ad1[y])):
    output1[x] = i

C=abs(np.array(output)-np.array(output1))

D=C.sum()
CP=D/len2
print('CP',CP)

count=0
for i in range(len2):
    if(C[i]==0):
        count+=1

CK=count/len2
print('CK',CK)